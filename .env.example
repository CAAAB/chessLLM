# Ollama Configuration
# Copy this file to .env and update with your settings if needed.

# Host and port for the Ollama API server
OLLAMA_API_HOST=http://localhost:11434

# Default Ollama model to use for explanations
OLLAMA_MODEL=llama2
